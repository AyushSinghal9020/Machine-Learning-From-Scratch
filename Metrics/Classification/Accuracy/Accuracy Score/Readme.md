# Accuracy Score 
Accuracy is the most commonly used metric, and it measures the proportion of correctly classified instances in a dataset. Precision measures the proportion of true positives among all positive predictions, while recall measures the proportion of true positives among all actual positives. The F1 score is a combination of precision and recall, and it provides a single measure of a model's performance.

Formula
****
$$accurcacy_-score = \frac {True_-Positves + True_-Negatives}{True_-Positves + True_-Negatives + False_-Positves + False_-Negatives}= \frac {T_P + T_N}{T_P + T_N + F_P + F_N}$$
****
